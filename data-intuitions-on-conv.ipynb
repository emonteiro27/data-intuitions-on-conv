{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4984c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5eb4e8",
   "metadata": {},
   "source": [
    "__Convolutional Neural Networks are Neural Networks specifically designed to work on images__\n",
    "\n",
    "\n",
    "- This is made possible thanks to __convolution operations__.\n",
    "\n",
    "\n",
    "- These specific mathematical operations apply a __filter__ (i.e. a set of kernels, one per channel) to an input image  and create an __output representation__. For Convolutional Neural Networks, this can also be called:\n",
    "    - a __\"convoluted representation/feature\"__,\n",
    "    - or a __\"convolution\"__,\n",
    "    - or also an __\"activation\"__ (as it corresponds to the activation of a given layer).\n",
    "    \n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "__Remarks__:\n",
    "\n",
    "\n",
    "- it is important to understand that __the same kernel (i.e. the same weights) is applied to different areas of the images__.\n",
    "\n",
    "\n",
    "- This is completely different from Dense Neural Networks:\n",
    "    - in __Dense/\"Fully Connected\" Neural Networks__, each weight of a given neuron is related to only one input coordinate (which, in images, would correspond to one pixel).\n",
    "    - in __Convolutional Neural Networks__, the weights of a kernel are not applied to only one feature input, i.e. one pixel, but to different pixels, \"step by step\".\n",
    "    \n",
    "    \n",
    "We can think of each kernel (or each filter in the case of colored images) as a magnifying glass through which we can see the image. Similarly to our eyes, kernels cannot capture everything in a picture at once, but they __scan different parts of a picture to understand the whole picture that is being analyzed__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4bb1f",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e6a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1632/1950120839.py:18: MatplotlibDeprecationWarning: Directly reading images from URLs is deprecated since 3.4 and will no longer be supported two minor releases later. Please open the URL for reading and pass the result to Pillow, e.g. with ``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\n",
      "  X.append(imread(c_path)[:, :, :1])\n",
      "/tmp/ipykernel_1632/1950120839.py:23: MatplotlibDeprecationWarning: Directly reading images from URLs is deprecated since 3.4 and will no longer be supported two minor releases later. Please open the URL for reading and pass the result to Pillow, e.g. with ``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\n",
      "  X.append(imread(t_path)[:, :, :1])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_data(path):\n",
    "    nb_circles = 100\n",
    "    nb_triangles = 100\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(nb_circles):\n",
    "        c_path = os.path.join(path, 'circles', f'circle_{i}.png')\n",
    "        X.append(imread(c_path)[:, :, :1])\n",
    "        y.append(0)\n",
    "    \n",
    "    for i in range(nb_triangles):\n",
    "        t_path = os.path.join(path, 'triangles', f'triangle_{i}.png')\n",
    "        X.append(imread(t_path)[:, :, :1])\n",
    "        y.append(1)\n",
    "        \n",
    "    c = list(zip(X, y))\n",
    "    np.random.shuffle(c)\n",
    "    X, y = zip(*c)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "        \n",
    "X, y = load_data(\"https://wagon-public-datasets.s3.amazonaws.com/deep-learning-circles-triangles/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e6ec0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 76, 78, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb99c6a",
   "metadata": {},
   "source": [
    "- We need only one channel to compute the \"blackness intensity\" of a pixel with 0 corresponding to a black pixel and 1 corresponding to a white pixel. The last dimension corresponds to some kind of \"Black to white channel\".\n",
    "\n",
    "\n",
    "- For colored images, the last dimension would be equal to 3 for Red, Green, Blue (RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e55fca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value: 0.0\n",
      "max value: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'min value: {np.min(X)}')\n",
    "print(f'max value: {np.max(X)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebf7e7",
   "metadata": {},
   "source": [
    "- There's no need to normalize the pixels' intensities. The data is already between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73ae43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
