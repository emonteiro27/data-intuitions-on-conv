{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a762ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02240f4a",
   "metadata": {},
   "source": [
    "__Convolutional Neural Networks are Neural Networks specifically designed to work on images__\n",
    "\n",
    "\n",
    "- This is made possible thanks to __convolution operations__.\n",
    "\n",
    "\n",
    "- These specific mathematical operations apply a __filter__ (i.e. a set of kernels, one per channel) to an input image  and create an __output representation__. For Convolutional Neural Networks, this can also be called:\n",
    "    - a __\"convoluted representation/feature\"__,\n",
    "    - or a __\"convolution\"__,\n",
    "    - or also an __\"activation\"__ (as it corresponds to the activation of a given layer).\n",
    "    \n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "__Remarks__:\n",
    "\n",
    "\n",
    "- it is important to understand that __the same kernel (i.e. the same weights) is applied to different areas of the images__.\n",
    "\n",
    "\n",
    "- This is completely different from Dense Neural Networks:\n",
    "    - in __Dense/\"Fully Connected\" Neural Networks__, each weight of a given neuron is related to only one input coordinate (which, in images, would correspond to one pixel).\n",
    "    - in __Convolutional Neural Networks__, the weights of a kernel are not applied to only one feature input, i.e. one pixel, but to different pixels, \"step by step\".\n",
    "    \n",
    "    \n",
    "We can think of each kernel (or each filter in the case of colored images) as a magnifying glass through which we can see the image. Similarly to our eyes, kernels cannot capture everything in a picture at once, but they __scan different parts of a picture to understand the whole picture that is being analyzed__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f0e6d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a981a8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
